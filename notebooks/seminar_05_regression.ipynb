{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\Sum}{\\sum\\limits}$\n",
    "$\\newcommand{\\Int}{\\int\\limits}$\n",
    "$\\newcommand{\\Intf}{\\int\\limits_{-\\infty}^{+\\infty}}$\n",
    "$\\newcommand{\\Prod}{\\prod\\limits}$\n",
    "$\\newcommand{\\Max}{\\max\\limits}$\n",
    "$\\newcommand{\\Min}{\\min\\limits}$\n",
    "$\\newcommand{\\Lim}{\\lim\\limits}$\n",
    "$\\newcommand{\\Var}{\\mathbb{V}}$\n",
    "$\\newcommand{\\Exp}{\\mathbb{E}}$\n",
    "$\\newcommand{\\argmax}{\\arg\\max}$\n",
    "$\\newcommand{\\Cov}{\\mathrm{Cov}}$\n",
    "$\\newcommand{\\makebold}[1]{\\boldsymbol{#1}}$\n",
    "$\\newcommand{\\mean}[1]{\\overline{#1}}$\n",
    "$\\newcommand{\\avg}[1]{\\left\\langle #1 \\right\\rangle}$\n",
    "$\\newcommand{\\Prob}{\\mathcal{P}}$\n",
    "$\\newcommand{\\lp}{\\left}$\n",
    "$\\newcommand{\\rp}{\\right}$\n",
    "$\\newcommand{\\eps}{\\varepsilon}$\n",
    "$\\newcommand{\\loss}{\\mathcal{L}}$\n",
    "$\\newcommand{\\Llr}{\\mathcal{L}}$\n",
    "$\\newcommand{\\llr}{\\ell}$\n",
    "\n",
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "$\\newcommand{\\ZZ}{\\mathbb{Z}}$\n",
    "$\\newcommand{\\NN}{\\mathbb{N}}$\n",
    "\n",
    "$\\newcommand{\\boldtheta}{\\boldsymbol{\\theta}}$\n",
    "$\\newcommand{\\boldtau}{\\boldsymbol{\\tau}}$\n",
    "$\\newcommand{\\boldX}{\\boldsymbol{X}}$\n",
    "$\\newcommand{\\boldY}{\\boldsymbol{Y}}$\n",
    "$\\newcommand{\\boldZ}{\\boldsymbol{Z}}$\n",
    "$\\newcommand{\\boldtheta}{\\boldsymbol{\\theta}}$\n",
    "$\\newcommand{\\boldtau}{\\boldsymbol{\\tau}}$\n",
    "\n",
    "$\\newcommand{\\boldx}{\\boldsymbol{x}}$\n",
    "$\\newcommand{\\boldu}{\\boldsymbol{u}}$\n",
    "$\\newcommand{\\boldv}{\\boldsymbol{v}}$\n",
    "$\\newcommand{\\boldy}{\\boldsymbol{y}}$\n",
    "$\\newcommand{\\boldz}{\\boldsymbol{z}}$\n",
    "$\\newcommand{\\boldp}{\\boldsymbol{p}}$\n",
    "\n",
    "$\\newcommand{\\Poisson}{\\mathrm{Poisson}}$\n",
    "$\\newcommand{\\Uniform}{\\mathrm{Uniform}}$\n",
    "$\\newcommand{\\Binomial}{\\mathrm{Binomial}}$\n",
    "$\\newcommand{\\Gammap}{\\mathrm{Gamma}}$\n",
    "$\\newcommand{\\Normal}{\\mathcal{N}}$\n",
    "$\\newcommand{\\LogN}{\\mathrm{LogN}}$\n",
    "$\\newcommand{\\Exponential}{\\mathrm{Exp}}$\n",
    "$\\newcommand{\\Erlang}{\\mathrm{Erlang}}$\n",
    "$\\newcommand{\\Cauchy}{C}$\n",
    "\n",
    "$\\newcommand{\\lf}{\\left\\{}$\n",
    "$\\newcommand{\\rf}{\\right\\}}$\n",
    "$\\newcommand{\\lp}{\\left(}$\n",
    "$\\newcommand{\\rp}{\\right)}$\n",
    "$\\newcommand{\\ls}{\\left[}$\n",
    "$\\newcommand{\\rs}{\\right]}$\n",
    "$\\newcommand{\\lv}{\\left|}$\n",
    "$\\newcommand{\\rv}{\\right|}$\n",
    "\n",
    "$\\newcommand{\\Ecdf}[1]{\\hat{F}_n(#1)}$\n",
    "$\\newcommand{\\boot}{\\mathrm{boot}}$\n",
    "$\\newcommand{\\bias}{\\mathrm{bias}}$\n",
    "$\\newcommand{\\se}{\\mathrm{se}}$\n",
    "$\\newcommand{\\MSE}{\\mathrm{MSE}}$\n",
    "$\\newcommand{\\qm}{\\mathrm{qm}}$\n",
    "$\\newcommand{\\as}{\\mathrm{as}}$\n",
    "$\\newcommand{\\trace}{\\mathrm{trace}}$\n",
    "\n",
    "$\\newcommand{\\esttheta}{\\hat{\\theta}}$\n",
    "$\\newcommand{\\estlambda}{\\hat{\\lambda}}$\n",
    "$\\newcommand{\\estmu}{\\hat{\\mu}}$\n",
    "$\\newcommand{\\estsigma}{\\hat{\\sigma}}$\n",
    "$\\newcommand{\\estalpha}{\\hat{\\alpha}}$\n",
    "$\\newcommand{\\estbeta}{\\hat{\\beta}}$\n",
    "$\\newcommand{\\estxi}{\\hat{\\xi}}$\n",
    "$\\newcommand{\\esttau}{\\hat{\\tau}}$\n",
    "$\\newcommand{\\estpsi}{\\hat{\\psi}}$\n",
    "$\\newcommand{\\esta}{\\hat{a}}$\n",
    "$\\newcommand{\\estb}{\\hat{b}}$\n",
    "$\\newcommand{\\estc}{\\hat{c}}$\n",
    "$\\newcommand{\\estd}{\\hat{d}}$\n",
    "$\\newcommand{\\estp}{\\hat{p}}$\n",
    "$\\newcommand{\\estT}{\\hat{T}}$\n",
    "$\\newcommand{\\estR}{\\hat{R}}$\n",
    "$\\newcommand{\\estF}{\\hat{F}}$\n",
    "$\\newcommand{\\estf}{\\hat{f}}$\n",
    "$\\newcommand{\\estC}{\\hat{C}}$\n",
    "$\\newcommand{\\estS}{\\hat{S}}$\n",
    "$\\newcommand{\\estY}{\\hat{Y}}$\n",
    "$\\newcommand{\\esty}{\\hat{y}}$\n",
    "$\\newcommand{\\estVar}{\\hat{\\Var}}$\n",
    "$\\newcommand{\\estExp}{\\hat{\\Exp}}$\n",
    "$\\newcommand{\\estSe}{\\hat{\\se}}$\n",
    "\n",
    "$\\newcommand{\\hata}{\\hat{a}}$\n",
    "$\\newcommand{\\hatb}{\\hat{b}}$\n",
    "$\\newcommand{\\hatc}{\\hat{c}}$\n",
    "$\\newcommand{\\hatd}{\\hat{d}}$\n",
    "$\\newcommand{\\hatf}{\\hat{f}}$\n",
    "$\\newcommand{\\hatg}{\\hat{g}}$\n",
    "$\\newcommand{\\hatk}{\\hat{k}}$\n",
    "$\\newcommand{\\hatp}{\\hat{p}}$\n",
    "$\\newcommand{\\hatr}{\\hat{r}}$\n",
    "$\\newcommand{\\hatt}{\\hat{t}}$\n",
    "$\\newcommand{\\haty}{\\hat{y}}$\n",
    "\n",
    "$\\newcommand{\\hatC}{\\hat{C}}$\n",
    "$\\newcommand{\\hatF}{\\hat{F}}$\n",
    "$\\newcommand{\\hatJ}{\\hat{J}}$\n",
    "$\\newcommand{\\hatK}{\\hat{K}}$\n",
    "$\\newcommand{\\hatY}{\\hat{Y}}$\n",
    "\n",
    "$\\newcommand{\\tiltau}{\\tilde{\\tau}}$\n",
    "$\\newcommand{\\tiltheta}{\\tilde{\\theta}}$\n",
    "$\\newcommand{\\tillambda}{\\tilde{\\lambda}}$\n",
    "$\\newcommand{\\tilsigma}{\\tilde{\\sigma}}$\n",
    "\n",
    "$\\newcommand{\\mlexi}{\\xi_{MLE}}$\n",
    "$\\newcommand{\\mletheta}{\\theta_{MLE}}$\n",
    "$\\newcommand{\\mlelambda}{\\lambda_{MLE}}$\n",
    "$\\newcommand{\\mlesigma}{\\sigma_{MLE}}$\n",
    "\n",
    "$\\newcommand{\\mmxi}{\\xi_{MM}}$\n",
    "$\\newcommand{\\mmtheta}{\\theta_{MM}}$\n",
    "$\\newcommand{\\mmlambda}{\\lambda_{MM}}$\n",
    "$\\newcommand{\\mmsigma}{\\sigma_{MM}}$\n",
    "$\\newcommand{\\mmgamma}{\\gamma_{MM}}$\n",
    "\n",
    "$\\newcommand{\\xs}[1]{\\boldx^{(#1)}}$\n",
    "$\\newcommand{\\ys}[1]{\\boldy^{(#1)}}$\n",
    "$\\newcommand{\\zs}[1]{\\boldz^{(#1)}}$\n",
    "$\\newcommand{\\Xs}[1]{\\boldX^{(#1)}}$\n",
    "$\\newcommand{\\Ys}[1]{\\boldY^{(#1)}}$\n",
    "$\\newcommand{\\Zs}[1]{\\boldZ^{(#1)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import copy\n",
    "\n",
    "from scipy import stats\n",
    "from itertools import product\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from itertools import combinations, product\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "# sklearn\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.kernel_ridge import KernelRidge, pairwise_kernels\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "%matplotlib inline\n",
    "\n",
    "titlesize = 24\n",
    "labelsize = 22\n",
    "legendsize = 22\n",
    "xticksize = 18\n",
    "yticksize = xticksize\n",
    "\n",
    "matplotlib.rcParams['legend.markerscale'] = 1.5     # the relative size of legend markers vs. original\n",
    "matplotlib.rcParams['legend.handletextpad'] = 0.5\n",
    "matplotlib.rcParams['legend.labelspacing'] = 0.4    # the vertical space between the legend entries in fraction of fontsize\n",
    "matplotlib.rcParams['legend.borderpad'] = 0.5       # border whitespace in fontsize units\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "matplotlib.rcParams['font.family'] = 'serif'\n",
    "matplotlib.rcParams['font.serif'] = 'Times New Roman'\n",
    "matplotlib.rcParams['axes.labelsize'] = labelsize\n",
    "matplotlib.rcParams['axes.titlesize'] = titlesize\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=xticksize)\n",
    "matplotlib.rc('ytick', labelsize=yticksize)\n",
    "matplotlib.rc('legend', fontsize=legendsize)\n",
    "\n",
    "matplotlib.rc('font', **{'family':'serif'})\n",
    "# matplotlib.rc('text', usetex=True)\n",
    "# matplotlib.rc('text.latex', unicode=True)\n",
    "# matplotlib.rc('text.latex', preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "# matplotlib.rc('text.latex', preamble=r'\\usepackage[english]{babel}')\n",
    "# matplotlib.rc('text.latex', preamble=r'\\usepackage{amsmath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Содержание\n",
    "* [Обусловленность и регуляризация](#conditioning)\n",
    "* [Отбор признаков в модели линейной регрессии](#model_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conditioning'></a>\n",
    "# Обусловленность и регуляризация [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим некоторый сигнал $f \\in \\mathbb{R}^n$. Мы не знаем его реальное значение, т.к. воспринимаем его с помощью некоторого прибора. Прибором в нашей терминологии является линейный оператор $A: \\mathbb{R}^n \\to \\mathbb{R}^n$, влияющий на истинный сигнал $f$ и преобразующий его в воспринимаемое нами предтавление.\n",
    "\n",
    "Т.е. мы видим результат измерений $\\xi = Af + \\nu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes  = np.array([10.0, 1.0])\n",
    "frequencies = np.array([1. / 32, 1. / 2])\n",
    "periods = 1.0 / frequencies\n",
    "angle_frequencies = 2 * np.pi * frequencies\n",
    "# Signal f dimension.\n",
    "n_points = 256\n",
    "\n",
    "time_start = 0\n",
    "time_end = np.max(periods)\n",
    "t = np.linspace(time_start, time_end, n_points).reshape(-1, 1)\n",
    "time_step = (time_end - time_start) / (n_points - 1)\n",
    "\n",
    "f = np.sum(amplitudes * np.sin(t * angle_frequencies), axis=1)\n",
    "\n",
    "plt.plot(t, f, linewidth=2, color='b')\n",
    "plt.grid(which='both', linestyle='--')\n",
    "plt.xlabel('x')\n",
    "tmp_ = plt.ylabel('sum of sines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так выглядит оператор $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.eye(n_points)\n",
    "filter_size = 10\n",
    "filter_span = filter_size // 2\n",
    "for i in range(n_points):\n",
    "    A[i, max(i - filter_span, 0): min(i + filter_span + 1, n_points)] = 1\n",
    "A /= filter_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A)\n",
    "tmp_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результат измерения сигнала прибором:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "nu = np.random.normal(0, sigma, f.shape)\n",
    "xi = A.dot(f) + nu\n",
    "\n",
    "plt.plot(xi, label='noisy')\n",
    "plt.plot(f, label='clean')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('signal value')\n",
    "tmp_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка наименьших квадратов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотелось бы по $\\xi$ построить оценку реального сигнала -- т.е. решить задачу регрессии.\n",
    "\n",
    "MLE оценки в случае нормального шума получены на лекции / семинаре / самостоятельно:\n",
    "$$\n",
    "\\xi = Af + \\nu, \\quad \\nu \\sim \\mathcal{N}(0, \\sigma^2)\\\\\n",
    "\\hat f = \\underbrace{(A^TA)^{-1}A^T}_{R} \\cdot \\xi\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.linalg.inv(A.T.dot(A)).dot(A.T)\n",
    "f_estimate = R.dot(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xi, label='noisy')\n",
    "plt.plot(f, label='clean')\n",
    "plt.plot(f_estimate, label='estimate')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('signal value')\n",
    "plt.title('Oops...')\n",
    "tmp_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что случилось? Случилось то, что матрица плохо обусловлена и всё сломалось.\n",
    "\n",
    "Можно напрямую вычислить псевдообратную матрицу для $A$: $A^{+} = (A^TA)^{-1}A^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.linalg.pinv(A)\n",
    "f_estimate = R.dot(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xi, label='noisy')\n",
    "plt.plot(f, label='clean')\n",
    "plt.plot(f_estimate, label='estimate')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('signal value')\n",
    "tmp_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле, понять, что всё будет плохо, можно было просто взглянув на [число обусловленности](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D0%BC%D0%B5%D1%80%D0%BD%D0%B0%D1%8F_%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F#.D0.9F.D1.80.D0.BE.D0.B1.D0.BB.D0.B5.D0.BC.D1.8B) $A$ -- отношение максимального и минимального СЗ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление $l_2$ регуляризации\n",
    "Попробуем перед обращением матрицы добавить к её диагонали небольшие числа:\n",
    "$$\n",
    "\\tilde R = (A^TA + \\lambda I)^{-1}A^T\n",
    "$$\n",
    "Тем самым мы надеемся получить невырожденную матрицу, практически не повлияв на её значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change that for some more appropriate value.\n",
    "reg_coeff = 0.001\n",
    "R = np.linalg.inv(A.T.dot(A) + reg_coeff * np.eye(A.shape[0])).dot(A.T)\n",
    "f_estimate = R.dot(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xi, label='noisy')\n",
    "plt.plot(f, label='clean')\n",
    "plt.plot(f_estimate, label='estimate')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('signal value')\n",
    "tmp_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_choice'></a>\n",
    "# Отбор признаков в модели линейной регрессии [[toc]](#toc)\n",
    "* [Необходимый функционал](#model_choice_func)\n",
    "    * [Критерии](#criterions)\n",
    "    * [Классы FullSearch и GreedySearch](#model_search)\n",
    "    * [Функции для визуализации динамики весов](#model_plot)\n",
    "* [Diabetes dataset](#diabetes)\n",
    "* [Prostate dataset](#prostate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_choice_func'></a>\n",
    "## Необходимый функционал [[toc]](#toc) [[up]](#model_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weights(X, y):\n",
    "    \"\"\"\n",
    "    Функция нахождения weights = (X^T X)^{-1} X^T y\n",
    "    \"\"\"\n",
    "    return np.linalg.inv(np.dot(X.T, X)).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='criterions'></a>\n",
    "### Критерии [[toc]](#toc) [[up]](#model_choice)\n",
    "\n",
    "Рассмотрим несколько критериев для оценивания модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Criterion:\n",
    "    def initialize(self, X, y):\n",
    "        self._check_Xy_pair(X, y)\n",
    "        self.X = X; self.y = y\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = find_weights(X, y)\n",
    "        self.sigma2 = np.sum((y - np.dot(X, self.weights))**2) / (n_samples - n_features)\n",
    "        self.sigma = np.sqrt(self.sigma2)\n",
    "        return self\n",
    "    def _check_Xy_pair(self, X, y):\n",
    "        assert isinstance(X, np.ndarray)\n",
    "        assert isinstance(y, np.ndarray)\n",
    "        assert X.ndim == 2\n",
    "        assert y.ndim == 1\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "    def __call__(self, indices):\n",
    "        assert False, \"Not implmented\"\n",
    "    def __repr__(self):\n",
    "        return 'Criterion'\n",
    "\n",
    "class CriterionCp(Criterion):\n",
    "    def __call__(self, indices):\n",
    "        X = self.X[:, indices]\n",
    "        n_samples, n_features = X.shape\n",
    "        weights = find_weights(X, self.y)\n",
    "        return (np.sum((np.dot(X, weights) - self.y)**2) + 2 * n_features * self.sigma2) / n_samples\n",
    "    def __repr__(self):\n",
    "        return 'Cp'\n",
    "\n",
    "class CriterionLOO(Criterion):\n",
    "    def __call__(self, indices):\n",
    "        X = self.X[:, indices]\n",
    "        weights = find_weights(X, self.y)\n",
    "        n_samples, n_features = X.shape\n",
    "        U = np.dot(np.dot(X, np.linalg.inv(np.dot(X.T, X))), X.T)\n",
    "        U = U[np.arange(n_samples), np.arange(n_samples)]\n",
    "        return np.sum(((self.y - np.dot(X, weights)) / (1 - U)) ** 2) / n_samples\n",
    "    def __repr__(self):\n",
    "        return 'LOO'\n",
    "\n",
    "class CriterionCV(Criterion):\n",
    "    def __init__(self, n_folds=5, random_state=1):\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "    def __call__(self, indices):\n",
    "        X = self.X[:, indices]\n",
    "        n_samples, n_features = X.shape\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)\n",
    "        R_CV = 0\n",
    "        for tr_indices, ts_indices in kfold.split(X):\n",
    "            X_tr = X[tr_indices]; y_tr = self.y[tr_indices]\n",
    "            X_ts = X[ts_indices]; y_ts = self.y[ts_indices]\n",
    "            weights = find_weights(X_tr, y_tr)\n",
    "            R_CV += np.sum((y_ts - np.dot(X_ts, weights)) ** 2)\n",
    "        return R_CV / n_samples\n",
    "    def __repr__(self):\n",
    "        return 'CV' + str(self.n_folds)\n",
    "    \n",
    "class CriterionTest(Criterion):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = np.array(X_test)\n",
    "        self.y_test = np.array(y_test)\n",
    "    def __call__(self, indices):\n",
    "        X = self.X[:, indices]\n",
    "        n_samples, n_features = X.shape\n",
    "        weights = find_weights(X, self.y)\n",
    "        return np.sum((self.y_test - np.dot(self.X_test[:, indices], weights))**2) / self.X_test.shape[0]\n",
    "    def __repr__(self):\n",
    "        return 'Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_search'></a>\n",
    "### Классы FullSearch и GreedySearch [[toc]](#toc) [[up]](#model_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSearch:\n",
    "    def __init__(self, X, y, criterion, X_test=None, y_test=None, feature_names=None, verbose=False):\n",
    "        criterion.initialize(X, y)\n",
    "        self.criterion = criterion\n",
    "        self.X = X; self.y = y\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        if feature_names is None:\n",
    "            feature_names = list(range(self.n_features))\n",
    "        assert len(feature_names) == self.n_features\n",
    "        self.feature_names = feature_names\n",
    "        self.fname2ind = {name:i for i, name in enumerate(self.feature_names)}\n",
    "        self.ind2fname = {i:name for i, name in enumerate(self.feature_names)}\n",
    "\n",
    "        if not ((X_test is None) | (y_test is None)):\n",
    "            self.criterion._check_Xy_pair(X_test, y_test)\n",
    "            assert self.X.shape[1] == self.n_features\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "        else:\n",
    "            self.X_test = None\n",
    "            self.y_test = None\n",
    "\n",
    "    def find_best_subset(self):\n",
    "        best_value = np.inf\n",
    "        best_subset = []\n",
    "        for n_features in range(1, self.n_features + 1):\n",
    "            for indices in combinations(list(range(self.n_features)), n_features):\n",
    "                criterion_value = self.criterion(indices)\n",
    "                if criterion_value < best_value:\n",
    "                    best_value = criterion_value\n",
    "                    best_subset = indices\n",
    "        feature_names = [self.ind2fname[i] for i in best_subset]\n",
    "        return OrderedDict([('feature_indices', best_subset), \n",
    "               ('feature_names', feature_names), \n",
    "               ('best_value', best_value)])\n",
    "\n",
    "class GreedySearch:\n",
    "    def __init__(self, X, y, criterion, feature_names=None, forward=True, verbose=False):\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.criterion = criterion.initialize(self.X, self.y)\n",
    "        self.n_samles, self.n_features = self.X.shape\n",
    "        if feature_names is None:\n",
    "            feature_names = list(range(self.n_features))\n",
    "        assert len(feature_names) == self.n_features\n",
    "        self.feature_names = feature_names\n",
    "        self.forward = forward\n",
    "        self.verbose = verbose\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.all_features = set(range(self.n_features))\n",
    "        self._find_sigma()\n",
    "    \n",
    "    def _find_sigma(self):\n",
    "        self.beta = find_weights(self.X, self.y)\n",
    "        self.sigma = np.sqrt(np.sum((self.y - np.dot(self.X, self.beta)) ** 2) / (self.n_samples - self.n_features))\n",
    "           \n",
    "    def __call__(self):\n",
    "        if self.forward:\n",
    "            self.curr_value = np.inf\n",
    "            self.curr_features = set()\n",
    "            while self._forward_step():\n",
    "                pass\n",
    "        else:\n",
    "            self.curr_value = np.inf\n",
    "            self.curr_features = set(range(self.n_features))\n",
    "            while self._backward_step():\n",
    "                pass\n",
    "            \n",
    "        best_subset = sorted(list(self.curr_features))\n",
    "        feature_names = [self.feature_names[i] for i in best_subset]\n",
    "        return OrderedDict([('feature_indices', best_subset), \n",
    "                            ('feature_names', feature_names), \n",
    "                            ('best_value', self.curr_value)])\n",
    "            \n",
    "    def _forward_step(self):\n",
    "        self.not_considered = self.all_features - self.curr_features # Еще не рассморенные признаки\n",
    "        best_feature = -1     \n",
    "        best_value = np.inf\n",
    "        for n_feature in sorted(list(self.not_considered)):\n",
    "            new_features = copy.deepcopy(self.curr_features)\n",
    "            new_features.add(n_feature)\n",
    "            new_features = np.array(sorted(list(new_features)))\n",
    "\n",
    "            value = self.criterion(new_features)\n",
    "            self.print('F_step: new feature set {} gives value = {}'.format(new_features, value))\n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_feature = n_feature\n",
    "        if best_value < self.curr_value:\n",
    "            self.curr_value = best_value\n",
    "            self.print('F_step: feature {} added to feature set {}\\n'.format(\n",
    "                best_feature, sorted(list(self.curr_features))))\n",
    "            self.curr_features.add(best_feature)\n",
    "            return True\n",
    "        else:\n",
    "            self.print('F_step: maximum reached for feature set {}; current value = {}\\n'.format(\n",
    "                self.curr_features, self.curr_value))\n",
    "            return False\n",
    "    \n",
    "    def _backward_step(self):\n",
    "        best_feature = -1\n",
    "        best_value = np.inf\n",
    "        for n_feature in sorted(list(self.curr_features)):\n",
    "            new_features = copy.deepcopy(self.curr_features)\n",
    "            new_features.remove(n_feature)\n",
    "            new_features = np.array(sorted(list(new_features)))\n",
    "            if len(new_features) == 0:\n",
    "                break\n",
    "            value = self.criterion(new_features)\n",
    "            self.print('B_step: new feature set {} gives value = {}'.format(new_features, value))\n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_feature = n_feature\n",
    "        if best_value < self.curr_value:\n",
    "            self.curr_value = best_value\n",
    "            self.print('B_step: feature {} removed from feature set {}\\n'.format(\n",
    "                best_feature, sorted(list(self.curr_features))))\n",
    "            self.curr_features.remove(best_feature)\n",
    "            return True\n",
    "        else:\n",
    "            self.print('B_step: maximum reached for feature set {}; current value = {}\\n'.format(\n",
    "                self.curr_features, self.curr_value))\n",
    "            return False\n",
    "        \n",
    "    def print(self, msg):\n",
    "        if self.verbose:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_plot'></a>\n",
    "### Функции для визуализации динамики весов [[toc]](#toc) [[up]](#model_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(make_model, alphas, **model_kwargs):\n",
    "    coefs = []\n",
    "    for a in alphas:\n",
    "        model = make_model(alpha=a, **model_kwargs)\n",
    "        model.fit(X, y)\n",
    "        coefs.append(model.coef_)\n",
    "    return np.array(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_path(ax, alphas, Model, **kwargs):\n",
    "    model_name = str(Model())\n",
    "    model_name = model_name[:model_name.find('(')]\n",
    "\n",
    "    coeffs = get_model_path(Model, alphas, **kwargs)\n",
    "\n",
    "    ax.plot(alphas, coeffs)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('regularization parameter')\n",
    "    ax.set_ylabel('weights')\n",
    "    ax.set_title('{} coefficients'.format(model_name))\n",
    "    ax.grid(which='major', linestyle='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='diabetes'></a>\n",
    "## Diabetes dataset [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "X = np.hstack([X, np.ones((X.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(3, 1, figsize=(9, 16))\n",
    "\n",
    "fit_intercept = False\n",
    "n_alphas = 200\n",
    "alphas = np.logspace(-5, 1, n_alphas)\n",
    "\n",
    "plot_model_path(axarr[0], alphas, linear_model.Ridge, **{'fit_intercept': fit_intercept})\n",
    "\n",
    "plot_model_path(axarr[1], alphas, linear_model.Lasso, **{'fit_intercept': fit_intercept})\n",
    "\n",
    "plot_model_path(axarr[2], alphas, linear_model.ElasticNet, **{'fit_intercept': fit_intercept})\n",
    "\n",
    "tmp_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация  [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = linear_model.Lasso(random_state=153, fit_intercept=False)\n",
    "model = linear_model.Ridge(random_state=153, fit_intercept=False)\n",
    "\n",
    "n_alphas = 64\n",
    "alphas = np.logspace(-5, 1, n_alphas)\n",
    "\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "n_folds = 3\n",
    "\n",
    "gscv = GridSearchCV(model, tuned_parameters, scoring='neg_mean_squared_error', cv=n_folds, refit=True, iid=True, return_train_score=True)\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(gscv.cv_results_).sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка и параметры лучшей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_score_, gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = gscv.predict(X_test)\n",
    "print(-np.mean((y_test - pred_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Отбор признаков  [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "\n",
    "criterions = [CriterionCp(), CriterionLOO(), CriterionCV(5), CriterionCV(10), CriterionTest(X_test, y_test)]\n",
    "for criterion in criterions:\n",
    "    full_searcher = FullSearch(X_train, y_train, criterion, X_test, y_test)\n",
    "    results = full_searcher.find_best_subset()\n",
    "    indices = results['feature_indices']\n",
    "    weights = find_weights(X_train[:,indices], y_train)\n",
    "    print(criterion)\n",
    "    for k, v in results.items():\n",
    "        print('\\t{}: {}'.format(k, v))\n",
    "    print('\\tMSE test: {}'.format(np.mean((np.dot(X_test[:,indices], weights) - y_test)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prostate'></a>\n",
    "## Prostate dataset [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep='\\t', header=0, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df.train == 'T'].drop(['lpsa', 'train'], axis=1).values\n",
    "y_train = df[df.train == 'T']['lpsa'].values\n",
    "\n",
    "X_test = df[df.train == 'F'].drop(['lpsa', 'train'], axis=1).values\n",
    "y_test = df[df.train == 'F']['lpsa'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Полный перебор множеств признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "\n",
    "criterions = [CriterionCp(), CriterionLOO(), CriterionCV(5), CriterionCV(10), CriterionTest(X_test, y_test)]\n",
    "for criterion in criterions:\n",
    "    full_searcher = FullSearch(X_train, y_train, criterion, X_test, y_test)\n",
    "    results = full_searcher.find_best_subset()\n",
    "    indices = results['feature_indices']\n",
    "    weights = find_weights(X_train[:,indices], y_train)\n",
    "    print(criterion)\n",
    "    for k, v in results.items():\n",
    "        print('\\t{}: {}'.format(k, v))\n",
    "    print('\\tMSE test: {}'.format(np.mean((np.dot(X_test[:,indices], weights) - y_test)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Жадный перебор множеств признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "criterions = [CriterionCp(), CriterionLOO(), CriterionCV(5), CriterionCV(10), CriterionTest(X_test, y_test)]\n",
    "for criterion in criterions:\n",
    "    searcher = GreedySearch(X_train, y_train, criterion, forward=True, verbose=verbose)\n",
    "    results = searcher()\n",
    "    best_features = results['feature_indices']\n",
    "    best_value = results['best_value']\n",
    "    weights = find_weights(X_train[:,best_features], y_train)\n",
    "    print(criterion, 'forward', best_features, best_value)\n",
    "    print('\\tMSE test: {}'.format(np.mean((np.dot(X_test[:,best_features], weights) - y_test)**2)))\n",
    "\n",
    "    searcher = GreedySearch(X_train, y_train, criterion, forward=False, verbose=verbose)\n",
    "    results = searcher()\n",
    "    best_features = results['feature_indices']\n",
    "    best_value = results['best_value']\n",
    "    weights = find_weights(X_train[:,best_features], y_train)\n",
    "    weights = find_weights(X_train[:,best_features], y_train)\n",
    "    print(criterion, 'backward', best_features, best_value)\n",
    "    print('\\tMSE test: {}'.format(np.mean((np.dot(X_test[:,best_features], weights) - y_test)**2)))\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
